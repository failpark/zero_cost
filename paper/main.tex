\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{minted}
\usepackage{svg}
\usepackage[style=ieee]{biblatex}
\addbibresource{literature.bib}

% Minted style configuration
\setminted{
	fontsize=\footnotesize,
	breaklines=true,
	frame=single,
	numbers=left,
	numbersep=5pt,
	tabsize=2
}

\begin{document}

\title{
	Zero-Cost State Management: Comparing Rust Typestate and C Runtime Checks at the Assembly Level
}

\author{
	\IEEEauthorblockN{Daniel Borgs}
	\IEEEauthorblockA{
		\textit{Faculty of Computer Science and Business Information Systems} \\
		\textit{Technical University of Applied Sciences Würzburg-Schweinfurt}\\
		Würzburg, Germany \\
		daniel.borgs@study.thws.de
	}
}

\maketitle

\begin{abstract}
Memory safety vulnerabilities constitute the majority of security flaws in systems software, with industry reports indicating rates of approximately 70\%.
C requires explicit runtime checks for state validation, introducing conditional branches and overhead.
Rust claims zero-cost abstractions: compile-time verification without runtime penalty.
This paper investigates whether Rust's typestate pattern produces assembly identical to unsafe C code.

Three file handle state machine implementations were compared:
defensive C with runtime validation, minimal C without checks, and Rust with compile-time typestate enforcement.
Assembly analysis at -O2 optimization on ARM64 measured instruction counts and conditional branches.

Results demonstrate that Rust produces assembly identical
to minimal C (2 instructions, 0 branches) while defensive C requires 7 instructions with 2 branches.
These findings validate that compile-time type checking eliminates runtime overhead while preventing invalid state transitions.
\end{abstract}

\begin{IEEEkeywords}
memory safety, typestate, Rust, C, zero-cost abstractions, compile-time verification, ARM64
\end{IEEEkeywords}

\section{Introduction}

Memory safety vulnerabilities remain the dominant class of security flaws in systems software.
According to the 2025 CWE Top 25 Most Dangerous Software Weaknesses, memory corruption vulnerabilities rank highly:
Out-of-bounds Write (CWE-787, \#5), Use After Free (CWE-416, \#7), and Out-of-bounds Read (CWE-125, \#8)\cite{cwe_2025}.
Microsoft reports that approximately 70\% of their security vulnerabilities are memory safety issues\cite{microsoft_safety}.
The U.S. Cybersecurity and Infrastructure Security Agency (CISA)
has issued guidance urging software manufacturers to adopt memory-safe languages\cite{cisa_memory}.

Systems programming languages such as C provide the low-level control necessary for performance-critical code,
including operating systems, embedded systems, and cryptographic libraries.
However, C places the entire burden of correctness on the programmer.
State management---ensuring operations occur only when preconditions are met---must be enforced through explicit runtime checks or external documentation.

This creates a fundamental tension.
Defensive programming adds conditional branches that verify state before each operation, incurring runtime overhead.
Omitting these checks improves performance but permits undefined behavior when invariants are violated.
Higher-level languages such as Java enforce safety through garbage collection and runtime checks,
but these mechanisms introduce runtime overhead that limits their applicability to resource-constrained and bare-metal systems programming\cite{oncd_report}.

Rust takes a different approach: encoding invariants in the type system so that invalid programs fail to compile.
The language's ownership system prevents use-after-free and data races at compile time\cite{rust_embedded}.
This paper hypothesizes that Rust's typestate pattern produces assembly identical to unchecked C while providing compile-time safety guarantees.
The central research question is: Can compile-time state verification eliminate runtime
overhead while preventing invalid state transitions at compile time?

\section{Background}

\subsection{State Management}

State management ensures that operations occur only when preconditions are met\cite{google_paper}.
A file handle, for instance, must transition through defined states
(Figure~\ref{fig:state-machine}): \texttt{create()} produces a Closed handle;
\texttt{open()} transitions to Open; \texttt{read()} loads data into Readable; \texttt{close()} returns to Closed.
Reading from a closed handle or closing an already-closed handle represents invalid state transitions that may cause undefined behavior in C, depending on the implementation.
Conversely, failing to close a handle causes resource leaks.

\begin{figure}[H]
	\centering
	\includesvg[width=1.00\columnwidth,inkscapelatex=false]{svg/state_machine_manual_bottom}
	\caption{File handle state machine. Transitions: \texttt{create()} produces Closed; \texttt{open()} transitions to Open; \texttt{read()} loads data into Readable; \texttt{close()} returns to Closed.}
	\label{fig:state-machine}
\end{figure}

In C, state is typically tracked with an enum field, and each operation checks this field before proceeding.
This approach is safe but introduces conditional branches that consume CPU cycles and may cause branch mispredictions.
Furthermore, standard C compilers cannot verify that programmers consistently perform these checks.

\subsection{The Typestate Pattern}

The typestate pattern, introduced by Strom and Yemini\cite{strom_typestate_1986},
encodes an object's state in its type, making state transitions explicit in the type system.
Rather than a single \texttt{FileHandle} type with a state field,
each state becomes a distinct type: \texttt{FileHandle<Closed>}, \texttt{FileHandle<Open>}, \texttt{FileHandle<Readable>}.

Operations consume the input type and produce the output type.
The \texttt{open} method takes \texttt{FileHandle<Closed>} by value (consuming it) and returns \texttt{FileHandle<Open>}.
This consumption is critical: once the handle transitions states, the original handle is invalidated,
preventing operations on stale state---analogous to how Rust's ownership prevents use-after-free at the memory level.
Attempting to call \texttt{read} on a \texttt{FileHandle<Closed>} produces a compile-time error; the method simply does not exist for that type.

This approach offers two potential advantages.
First, invalid state transitions become compile errors rather than runtime failures.
Second, since the compiler statically verifies state validity,
runtime checks become unnecessary---suggesting that typestate-encoded programs could match the performance of unchecked C.

\subsection{Zero-Cost Abstractions}

Rust's design philosophy emphasizes zero-cost abstractions:
high-level constructs that compile to code as efficient as hand-written low-level equivalents\cite{rust_embedded}.
Generic type parameters are instantiated through monomorphization---the process of generating specialized machine code
for each concrete type used at compile time, rather than using runtime dispatch.
Since \texttt{PhantomData<State>} is zero-sized, the state markers occupy no memory and produce no runtime code\cite{rust_reference_phantomdata}.

If this principle holds for typestate, Rust's approach would achieve what defensive C cannot: safety without runtime overhead.

\section{Related Work}

Strom and Yemini introduced typestate in 1986 as a compile-time technique to detect invalid execution sequences\cite{strom_typestate_1986}.
Their formulation tracked variables through states like ``uninitialized'' or ``deallocated,'' with the compiler verifying state flow through program paths.
Earlier work by Strom\cite{strom_mechanisms_1983} established the foundations for compile-time security enforcement through type-based mechanisms.

Rust applies affine types, meaning values can be used at most once, enabling memory safety without garbage collection.
The borrow checker prevents use-after-free by tracking ownership at compile time.
While Rust lacks explicit typestate abstractions, its type system supports implementing them through generic parameters and \texttt{PhantomData}.

Prior empirical work comparing typestate performance to C at the assembly level remains limited.
Existing literature focuses primarily on the theoretical foundations of typestate\cite{strom_typestate_1986, strom_mechanisms_1983},
with minimal attention to empirical performance validation.
This paper addresses that gap through assembly-level analysis of concrete implementations.

\section{Methodology}

To isolate state management overhead from I/O latency, three variants of a minimal file handle abstraction were implemented.
The handle stores only an integer \texttt{data} field, and operations simulate state transitions without actual file system calls.
This synthetic approach enables direct comparison of state-checking overhead without confounding factors.

Each implementation was compiled at -O2 optimization level: Apple Clang 17.0.0 for C, and rustc 1.91.1 with Rust edition 2024 for Rust.
Assembly was extracted using \texttt{objdump -d} on macOS ARM64 (\texttt{aarch64-apple-darwin}).

Rust was compiled as a \texttt{cdylib} (C-compatible dynamic library) to prevent whole-program optimization from constant-folding the entire state machine.
Functions were marked with \texttt{\#[no\_mangle]} to preserve function boundaries for comparison.
The C implementations were compiled as shared libraries with equivalent settings (\texttt{-shared -fPIC}).

This study is limited to ARM64 architecture; results on other platforms such as x86-64 may differ.

Instructions and conditional branches were counted manually for each function, with assembly listings verified against compiler output.
Four state transition functions were analyzed: \texttt{open}, \texttt{read}, \texttt{get\_data}, and \texttt{close}.
These four functions represent all state transitions in the file handle state machine, providing complete coverage of the pattern's behavior.

\subsection{Defensive C Implementation}

The defensive implementation tracks state explicitly with an enum and validates preconditions before each operation:

\begin{listing}[H]
\begin{minted}{c}
typedef enum {
	STATE_CLOSED, STATE_OPEN, STATE_READABLE
} state_t;

typedef struct {
	state_t state;
	int data;
} file_handle_t;

int file_handle_get_data(file_handle_t* h) {
	if (h->state != STATE_READABLE) {
		return -1;  // Can only get data when readable
	}
	return h->data;
}
\end{minted}
\caption{Defensive C state management. The error return value of -1 represents one possible error-handling strategy; alternatives include setting \texttt{errno} or using out-parameters.}
\end{listing}

Each operation contains a conditional branch checking the current state.
The compiled assembly includes comparison instructions and conditional jumps for each check.

\subsection{Minimal C Implementation}

The minimal implementation omits all state tracking:

\begin{listing}[H]
\begin{minted}{c}
typedef struct {
	int data;
} file_handle_t;

int file_handle_get_data(file_handle_t* h) {
	return h->data;
}
\end{minted}
\caption{Minimal C without state checks}
\end{listing}

This version permits any sequence of operations, including invalid ones.
It represents the performance ceiling---the minimum possible overhead---but provides no safety guarantees.

\subsection{Rust Typestate Implementation}

The Rust implementation encodes each state as a zero-sized type:

\begin{listing}[H]
\begin{minted}{rust}
struct Closed;
struct Open;
struct Readable;

struct FileHandle<State> {
	data: i32,
	_state: PhantomData<State>,
}

impl FileHandle<Closed> {
	fn open(self) -> FileHandle<Open> {
		FileHandle { data: self.data, _state: PhantomData }
	}
}

impl FileHandle<Open> {
	fn read(self) -> FileHandle<Readable> {
		FileHandle { data: 42, _state: PhantomData }
	}
}

impl FileHandle<Readable> {
	fn get_data(&self) -> i32 {
		self.data
	}
}
\end{minted}
\caption{Rust typestate pattern with state transition methods}
\end{listing}

The \texttt{PhantomData<State>} field is a zero-sized type marker that exists only for the type checker.
The \texttt{get\_data} method is only defined for \texttt{FileHandle<Readable>}; calling it on other states produces a compile error.
State transition methods consume the handle by value (\texttt{self} rather than \texttt{\&self}), preventing reuse after transition.
The \texttt{get\_data} accessor uses borrowing (\texttt{\&self}) since reading does not change state.

\section{Results}

The defensive C implementation produced the following assembly for
\texttt{get\_data} (comments added for clarity; original \texttt{objdump} output contains only instructions):

\begin{minted}[fontsize=\scriptsize]{gas}
ldr  w8, [x0]        ; Load state field
cmp  w8, #0x2        ; Compare to READABLE
b.ne error           ; Branch if invalid
ldr  w0, [x0, #4]    ; Load data
ret
error:               ; Label (not an instruction)
mov  w0, #-1         ; Return error
ret
\end{minted}

This yields 7 instructions: 2 memory loads, 1 comparison, 1 conditional branch, 1 move, and 2 returns.
The label \texttt{error:} marks a branch target and is not counted as an instruction.
The 7-instruction count includes the error handling path; the happy path (valid state) requires 5 instructions,
but both paths must be present in the compiled binary.

The minimal C and Rust implementations both produced identical assembly:

\begin{minted}[fontsize=\scriptsize]{gas}
ldr  w0, [x0]        ; Load data directly
ret
\end{minted}

This yields 2 instructions: 1 memory operation and 1 return, with zero conditional branches.

\begin{figure}[H]
	\centering
	\includesvg[width=1.00\columnwidth,inkscapelatex=false]{figures/instruction_count_without_title.svg}
	\caption{Total instruction count comparison at -O2. Rust matches minimal C with 2 instructions, while defensive C requires 7 instructions due to state validation overhead.}
	\label{fig:instruction-count}
\end{figure}

Figure~\ref{fig:instruction-count} demonstrates that Rust achieves the same instruction count
as minimal C---both implementations compile to exactly 2 instructions.
The defensive C implementation requires 3.5$\times$ the instructions due to explicit state checking logic.

\begin{figure}[H]
	\centering
	\includesvg[width=\columnwidth,inkscapelatex=false]{figures/instruction_breakdown_without_title.svg}
	\caption{Instruction category breakdown. The critical finding: Rust has zero conditional branch instructions, matching minimal C, while defensive C includes 2 branch instructions for runtime state validation.}
	\label{fig:instruction-breakdown}
\end{figure}

Figure~\ref{fig:instruction-breakdown} reveals the key insight:
Rust's typestate implementation contains zero conditional branch instructions, identical to minimal C.
The defensive C version includes a compare instruction (\texttt{cmp}) and one conditional branch (\texttt{b.ne}) that verify state validity at runtime.
These instructions represent the performance cost of runtime safety checks that Rust eliminates through compile-time verification.

\subsection{Multi-Function Analysis}

To verify that results generalize beyond a single function, all four state transition operations were analyzed using the same methodology.
Table~\ref{tab:multi-function} presents the complete results.

\begin{table}[H]
\centering
\caption{Instruction counts across all state transition functions at -O2 optimization.}
\label{tab:multi-function}
\begin{tabular}{lccc}
\hline
\textbf{Function} & \textbf{Defensive C} & \textbf{Minimal C / Rust} & \textbf{Overhead} \\
\hline
\texttt{get\_data} & 7 & 2 & 3.5$\times$ \\
\texttt{open} & 9 & 2 & 4.5$\times$ \\
\texttt{read} & 11 & 2 & 5.5$\times$ \\
\texttt{close} & 8 & 2 & 4.0$\times$ \\
\hline
\end{tabular}
\end{table}

Across all functions, the pattern remains consistent:
Rust and minimal C produce identical assembly, while defensive C requires 3.5--5.5$\times$ the instructions due to state validation overhead.

In the Rust build, LLVM recognized that \texttt{open} and \texttt{close} have identical implementations
(both produce a handle with the same data) and merged them into a single function.
Apple Clang (also LLVM-based) performed the same optimization for the minimal C implementation.
This code deduplication demonstrates LLVM's optimization capabilities and does not affect the validity of the comparison.

\section{Discussion}

The empirical results validate the zero-cost abstraction principle:
Rust's type-level state encoding produces assembly identical to minimal C while providing compile-time safety guarantees equivalent to defensive C's runtime checks.

\subsection{Implications for Security}

Google's Android team reported that as the proportion of new memory-unsafe code decreased,
memory safety vulnerabilities dropped from 76\% in 2019 to 35\% in 2022\cite{google_android}.
While this correlation does not prove causation, it suggests that language choice significantly impacts vulnerability rates.

The typestate pattern extends this principle beyond memory safety to protocol correctness.
APIs that enforce valid state sequences through types prevent an entire class of logic errors
---not through runtime checks that might be forgotten, but through compile-time guarantees that cannot be circumvented.
Future work could investigate whether the typestate pattern applies to other vulnerability classes such as authorization checks,
input validation, and command sanitization by encoding security state transitions in the type system.

\subsection{Generalizability}

The consistency across all four analyzed functions strengthens confidence that
the zero-cost property is not an artifact of a single cherry-picked example.
The identical assembly output for Rust and minimal C across different state transitions suggests
that the typestate pattern reliably compiles away at optimization levels typical of production builds.

However, several factors limit generalizability.
First, only a single state machine pattern was analyzed;
more complex state machines with additional fields or nested states may exhibit different behavior.
Second, the synthetic benchmark isolates state management from real-world concerns such as I/O, error propagation, and concurrent access.
Third, LLVM's optimization behavior may differ across versions or with different optimization flags.

\section{Conclusion}

This paper presents three implementations of a file handle state machine to investigate whether
Rust's compile-time type checking can eliminate runtime state-validation overhead.
The defensive C approach provides safety through explicit runtime checks at the cost of conditional branches.
Minimal C omits these checks for maximum performance but permits invalid operations.
Rust's typestate pattern encodes state in the type system, rejecting invalid sequences at compile time.

The empirical results validate the zero-cost abstraction principle:
Rust's typestate implementation produces assembly identical to minimal C (2 instructions, 0 branches)
while providing compile-time guarantees equivalent to defensive C's runtime checks (7 instructions, 2 branches).
Across four functions, defensive C consistently requires 3.5--5.5$\times$ more instructions due to state validation overhead.

This analysis has limitations.
Only ARM64 architecture was tested; results may differ on x86-64 or other platforms and warrant further investigation.
Additionally, only -O2 optimization was tested; behavior at -O3 or with link-time optimization (LTO) remains unexplored.
The benchmark uses a synthetic state machine rather than real-world code with I/O operations.
The typestate pattern applies specifically to state machines; other safety patterns may have different overhead characteristics.
Only a single state machine design was evaluated; more complex patterns warrant further investigation.
The separate compilation methodology (\texttt{cdylib}) represents a conservative lower bound; whole-program optimization could yield further improvements.

These findings suggest that the traditional safety-performance tradeoff is not fundamental.
With sufficiently expressive type systems, safety can become a compile-time property with zero runtime cost.

\renewcommand*{\UrlFont}{\rmfamily}
\printbibliography

\end{document}
